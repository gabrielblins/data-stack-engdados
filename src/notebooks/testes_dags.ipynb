{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97894973-6197-474a-9622-a2740ec7ced7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'result': {'price': {'last': 141682.7351, 'high': 152102.7456, 'low': 141682.7351, 'change': {'percentage': -0.06719146417766352, 'absolute': -10205.599600000016}}, 'volume': 0.265100000000003, 'volumeQuote': 39246.55590935982}, 'allowance': {'cost': 0.005, 'remaining': 9.995, 'upgrade': 'For unlimited API access, create an account at https://cryptowat.ch'}, 'exchange_name': 'bisq'}, {'result': {'price': {'last': 146663, 'high': 146989, 'low': 146287, 'change': {'percentage': -0.0003680555082233143, 'absolute': -54}}, 'volume': 40.743329999908006, 'volumeQuote': 5975179.0876807785}, 'allowance': {'cost': 0.005, 'remaining': 9.99, 'upgrade': 'For unlimited API access, create an account at https://cryptowat.ch'}, 'exchange_name': 'binance'}, {'result': {'price': {'last': 146613, 'high': 147139, 'low': 146268, 'change': {'percentage': -0.001226216508961599, 'absolute': -180}}, 'volume': 5.211156999999866, 'volumeQuote': 764278.8033840092}, 'allowance': {'cost': 0.005, 'remaining': 9.985, 'upgrade': 'For unlimited API access, create an account at https://cryptowat.ch'}, 'exchange_name': 'hitbtc'}, {'result': {'price': {'last': 0, 'high': 0, 'low': 0, 'change': {'percentage': 0, 'absolute': 0}}, 'volume': 0, 'volumeQuote': 0}, 'allowance': {'cost': 0.005, 'remaining': 9.98, 'upgrade': 'For unlimited API access, create an account at https://cryptowat.ch'}, 'exchange_name': 'huobi'}, {'result': {'price': {'last': 147491, 'high': 148489.9, 'low': 146060.3, 'change': {'percentage': 0.004543538211422022, 'absolute': 667.1000000000058}}, 'volume': 0.15464000000000358, 'volumeQuote': 22783.996200999492}, 'allowance': {'cost': 0.005, 'remaining': 9.975, 'upgrade': 'For unlimited API access, create an account at https://cryptowat.ch'}, 'exchange_name': 'kucoin'}]\n"
     ]
    }
   ],
   "source": [
    "import json, requests\n",
    "\n",
    "# Caminho relativo para o arquivo JSON\n",
    "path = 'symbol_exchanges_dict.json'\n",
    "\n",
    "\n",
    "with open(path, 'r') as json_file:\n",
    "    symbol_exchanges_dict = json.load(json_file)\n",
    "\n",
    "\n",
    "symbol_exchanges_dict\n",
    "sumary_results = []\n",
    "\n",
    "for exchange_name in symbol_exchanges_dict['btcbrl']:\n",
    "    base_url = f\"https://api.cryptowat.ch/markets/{exchange_name}/btcbrl/summary\"\n",
    "    response = requests.get(base_url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        data['exchange_name'] = exchange_name\n",
    "        sumary_results.append(data)\n",
    "    else:\n",
    "        sumary_results.append(None)\n",
    "\n",
    "print(sumary_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67765bf5-f6f4-4ba2-a0ef-b36418330dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /opt/conda/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (1.28.1)\n",
      "Collecting minio\n",
      "  Downloading minio-7.1.15-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3) (0.6.1)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.1 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.31.1)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from minio) (1.26.11)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from minio) (2022.9.24)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.1->boto3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.1->boto3) (1.16.0)\n",
      "Installing collected packages: minio\n",
      "Successfully installed minio-7.1.15\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark boto3 minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68702868-cd0d-4809-9e6e-a1b031a289fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark inicializado com sucesso com as credenciais do S3\n",
      "CPU times: user 68.7 ms, sys: 20.2 ms, total: 88.9 ms\n",
      "Wall time: 120 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import boto3\n",
    "import findspark\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "\n",
    "os.environ['PYARROW_IGNORE_TIMEZONE'] = str(1)\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"testing\") \\\n",
    "    .config(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", 'airflow') \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", 'sample_key') \\\n",
    "    .config(\"spark.hadoop.fs.s3a.proxy.host\", \"minio1\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"minio1\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.proxy.port\", \"9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark inicializado com sucesso com as credenciais do S3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b04e649-a880-4191-9c10-484836a2f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exch = spark.read.json(\"s3a://raw/symbol_exchanges_dict.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89133daf-b54e-4d3f-bb8d-c1b1e810c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from minio import Minio\n",
    "import datetime\n",
    "\n",
    "client = Minio('minio1:9000',\n",
    "               access_key='airflow',\n",
    "               secret_key='sample_key',\n",
    "               secure=False)\n",
    "\n",
    "object_data = client.get_object('raw', 'symbol_exchanges_dict.json')\n",
    "json_data = object_data.data.decode('utf-8')\n",
    "symbol_exchanges_dict=eval(json_data)\n",
    "\n",
    "import json, requests, io\n",
    "for exchange_name in symbol_exchanges_dict['btcbrl']:\n",
    "    base_url = f\"https://api.cryptowat.ch/markets/{exchange_name}/btcbrl/summary\"\n",
    "    response = requests.get(base_url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        data['exchange_name'] = exchange_name\n",
    "        # current_datetime = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        file_obj = io.BytesIO(str(data).encode())\n",
    "        client.put_object('raw',f'exchanges/{exchange_name}.json',file_obj, file_obj.getbuffer().nbytes)\n",
    "    else:\n",
    "        print(\"Não foi possível obter o exchange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77701242-0f5c-4b7d-af5f-4424d5257e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8ba8321-ad12-4469-b933-1c8e6333f7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-16_02-50-16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d2dd93b0-48ef-4243-9545-6878d390c015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "295f41ce-0ba8-42c4-a5dc-26d27e5e35d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import os\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from minio import Minio\n",
    "\n",
    "os.environ['PYARROW_IGNORE_TIMEZONE'] = str(1)\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"elt_raw_silver_exchanges\") \\\n",
    "    .config(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", 'airflow') \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", 'sample_key') \\\n",
    "    .config(\"spark.hadoop.fs.s3a.proxy.host\", \"minio1\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"minio1\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.proxy.port\", \"9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "client = Minio('minio1:9000',\n",
    "               access_key='airflow',\n",
    "               secret_key='sample_key',\n",
    "               secure=False)\n",
    "\n",
    "def flatten_test(df, field, sep=\"_\"):\n",
    "\n",
    "    # compute Complex Fields (Arrays, Structs and Maptypes) in Schema\n",
    "    complex_fields = dict(\n",
    "        [\n",
    "            (field.name, field.dataType)\n",
    "            for field in df.schema.fields\n",
    "            if type(field.dataType) == ArrayType\n",
    "            or type(field.dataType) == StructType\n",
    "            or type(field.dataType) == MapType\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    while len(complex_fields) != 0:\n",
    "        col_name = list(complex_fields.keys())[0]\n",
    "        # print (\"Processing :\"+col_name+\" Type : \"+str(type(complex_fields[col_name])))\n",
    "\n",
    "        # if StructType then convert all sub element to columns.\n",
    "        # i.e. flatten structs\n",
    "        if type(complex_fields[col_name]) == StructType:\n",
    "            expanded = [\n",
    "                col(col_name + \".\" + k).alias(col_name + sep + k)\n",
    "                for k in [n.name for n in complex_fields[col_name]]\n",
    "            ]\n",
    "            df = df.select(\"*\", *expanded).drop(col_name)\n",
    "\n",
    "        # if ArrayType then add the Array Elements as Rows using the explode function\n",
    "        # i.e. explode Arrays\n",
    "        elif type(complex_fields[col_name]) == ArrayType:\n",
    "            df = df.withColumn(col_name, explode_outer(col_name))\n",
    "\n",
    "        # if MapType then convert all sub element to columns.\n",
    "        # i.e. flatten\n",
    "        elif type(complex_fields[col_name]) == MapType:\n",
    "            keys_df = df.select(explode_outer(map_keys(col(col_name)))).distinct()\n",
    "            keys = list(map(lambda row: row[0], keys_df.collect()))\n",
    "            key_cols = list(\n",
    "                map(\n",
    "                    lambda f: col(col_name).getItem(f).alias(str(col_name + sep + f)),\n",
    "                    keys,\n",
    "                )\n",
    "            )\n",
    "            drop_column_list = [col_name]\n",
    "            df = df.select(\n",
    "                [\n",
    "                    col_name\n",
    "                    for col_name in df.columns\n",
    "                    if col_name not in drop_column_list\n",
    "                ]\n",
    "                + key_cols\n",
    "            )\n",
    "\n",
    "        # recompute remaining Complex Fields in Schema\n",
    "        complex_fields = dict(\n",
    "            [\n",
    "                (field.name, field.dataType)\n",
    "                for field in df.schema.fields\n",
    "                if type(field.dataType) == ArrayType\n",
    "                or type(field.dataType) == StructType\n",
    "                or type(field.dataType) == MapType\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "for obj in client.list_objects('raw', prefix=f'exchanges/'):\n",
    "    exch = spark.read.json(f\"s3a://raw/{obj.object_name}\")\n",
    "    exch = exch.drop('allowance')\n",
    "    fields = exch.select(\"result\").schema.fields\n",
    "    df_flat = flatten_test(exch,fields)\n",
    "    df_flat = df_flat.withColumn('datetime', lit(obj.last_modified))\n",
    "    df_flat.write.parquet(f\"s3a://silver/{obj.object_name[:-5]}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "785030d6-ba85-4ded-bf02-b7da4c2a80f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exchanges/binance\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "93c05cdd-3650-43d1-8903-ae42e6ec05e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "20e6ff77-51b7-460d-8327-6e2b351c6831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "06e62864-39b7-4b8f-9c56-0fd0b21c4137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- exchange_name: string (nullable = true)\n",
      " |-- result_volume: double (nullable = true)\n",
      " |-- result_volumeQuote: double (nullable = true)\n",
      " |-- result_price_high: long (nullable = true)\n",
      " |-- result_price_last: long (nullable = true)\n",
      " |-- result_price_low: long (nullable = true)\n",
      " |-- result_price_change_absolute: long (nullable = true)\n",
      " |-- result_price_change_percentage: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_flat.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "096317b3-68a5-4c52-aeff-215eb9906405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+------------------+-----------------+-----------------+----------------+----------------------------+------------------------------+\n",
      "|exchange_name|    result_volume|result_volumeQuote|result_price_high|result_price_last|result_price_low|result_price_change_absolute|result_price_change_percentage|\n",
      "+-------------+-----------------+------------------+-----------------+-----------------+----------------+----------------------------+------------------------------+\n",
      "|      binance|45.80987999990816| 6714543.838720769|           146989|           146329|          145645|                         -14|          -9.56656621772138E-5|\n",
      "+-------------+-----------------+------------------+-----------------+-----------------+----------------+----------------------------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c8c2c-acfa-47a5-aad5-cc43a8b728c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
